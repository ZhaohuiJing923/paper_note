# 2021-11-4
Title:The Cityscapes Dataset for Semantic Urban Scene Understanding
Auther:Marius Cordts
Comments:发表在CVPR2016上的文章，提出了Cityscapes数据集，语义城市场景理解。

他们做了：
1. 创造了最大最丰富的有高质量和粗标注的街景数据
2. 为像素级和实例级的语义标注提出了合理的评估方法
3. 深入分析了他们数据集的特性
4. 在他们的benchmark上测试了众多SOTA方法。

他们声称：
1. 最先进的方法在我们的数据集上的性能相对顺序与在更通用的数据集(如PASCAL VOC)上的性能明显不同。我们的结论是，通过这种通用数据集可能无法实现城市场景理解的重大进展。
2. 目前在KITTI和CamVid上的语义标记的最先进水平很容易达到，甚至在某种程度上通过应用现成的全卷积网络[41]只在城市景观上训练，如第3.5节所示。这突出了我们的数据集的兼容性和独特优势。
3. Cityscapes将给我们的领域带来重大的新挑战，因为它目前还远远没有被解决。


# 2021-11-5
Title：MINIMAL GEOMETRY-DISTORTION CONSTRAINT FOR UNSUPERVISED IMAGE-TO-IMAGE TRANSLATION
Auther：郭家贤
Comments：ICLR2021，主要做了：

image to image translation问题中的几何失真问题，首先把用之前一些方法translation前后的图片像素值绘图，发现一个目标区域中颜色在translation之后可以随机的映射各种颜色，之前方法这种颜色的随机
transformation造成了几何失真。所有，作者提出，减少颜色的随机transformation是减轻I2I中几何失真的一个办法。
提出，minimal geometry-distortion constraint (MGC)，限制在translation过程中保持像素级结构。举个简单例子就是：一张图片中叶子的颜色可以是红色（秋天），也可以是绿色（夏天），但是translation
前后，叶子的位置应该是一致的。这确实可以解决I2I中几何失真问题。
推导rSMI，数学公式很多。

问题：
1.为什么要设计新的MI，已有的MI不能实现吗？

总的来说，作者发现了现有I2I中几何失真的问题，并且分析了可能是translation过程中颜色随机transformation造成该问题，所有，提出MGC，通过rSMI来衡量translation前后图片的信息，以此来限制translation
时保持几何信息。


# 2021-11-8
Title：Unpaired Image-to-Image Translation using Adversarial Consistency Loss
Auther：Yihao Zhao
Comments：ACL-GAN，ECCV2020的一篇文章。主要是提出了一种新的loss用于unpaired I2I。

主要是考虑到cycle-consistency loss的不足：‘due to the strict pixel-level constraint, it cannot perform shape changes, remove large objects, or ignore irrelevant texture.’说主要
问题在于，它假设translated images contain all the information of the input images in order to reconstruct the input images。这导致保留source domain feature，比如大目标的痕迹（眼镜）
纹理（脸上的胡子），不好。此外，cycle-consistency loss约束source domain的形状改变（头发和脸型几乎没有变化）。
我认为它文章的重点是说，想让生成的image包含source domain的信息，从分布的角度，而不是保留pixel-level的一致性。translated image不需要和特定的source domin image像。至于实现上的关键是：acl
loss，判别器判别，(xS; ^xS)和(xS; ~xS)的真假，~xs是从x合成的，多模式输出，说是为了增加可能性。进一步，可以，让判别器关注feature level，即^xs不需要和特定的source image像。


Title：Contrastive Learning for Unpaired Image-to-Image Translation
Auther：Taesung Park
Comments：ECCV2020的文章，CUT，将对比学习思路引入到unpaired I2I中，通过对比学习来最大化输入输出间的互信息。

主要是希望take on the appearance of the target domain (a zebra), while retaining the structure, or content, of the specific input horse。通常，appearance由对抗loss玉树，content是
cycle-consistency保持。但是cycle-consistency，是双向，太严格，所有，提出straightforward的方式，实现保留input的结构信息，同时能有target的appearance信息。
实现：contrastive loss, InfoNCE loss, which aims to learn an embedding or an encoder that associates corresponding patches to each other, while disassociating them from others.
encoder在学习时关注the commonalitiesbetween the two domains, such as object parts and shapes, while being invariant to the differences, such as the textures of the animals.
重点是图2，We set up an (N+1)-way classication problem, where N negative patches are sampled from the same input image at different locations。

